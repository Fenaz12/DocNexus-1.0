{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c698fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Auto-reload enabled. Path set.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Path setup logic\n",
    "current_dir = os.getcwd()\n",
    "if os.path.basename(current_dir) == \"app\":\n",
    "    project_root = os.path.abspath(\"..\")\n",
    "elif \"app\" not in os.listdir(current_dir):\n",
    "    project_root = os.path.abspath(\"..\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Auto-reload enabled. Path set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"rag-eval-sml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41777574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_from_input(inputs: dict) -> str:\n",
    "    \"\"\"Extracts the user question from the Chat format or Flat format.\"\"\"\n",
    "    # Case 1: Chat Format (Your current JSONL)\n",
    "    if \"messages\" in inputs:\n",
    "        # Get the last message where role is 'user'\n",
    "        for msg in reversed(inputs[\"messages\"]):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                return msg[\"content\"]\n",
    "    \n",
    "    # Case 2: Flat Format (CSV style)\n",
    "    return inputs.get(\"question\") or inputs.get(\"Question\") or inputs.get(\"input\") or \"\"\n",
    "\n",
    "def get_ground_truth(reference_outputs: dict) -> str:\n",
    "    \"\"\"Extracts the ground truth answer.\"\"\"\n",
    "    # Case 1: Chat Format (Your current JSONL uses 'message' -> 'content')\n",
    "    if \"message\" in reference_outputs:\n",
    "        return reference_outputs[\"message\"][\"content\"]\n",
    "    \n",
    "    # Case 2: Flat Format\n",
    "    return reference_outputs.get(\"answer\") or reference_outputs.get(\"output\") or \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64a19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa1922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- 1. Define Helper Functions (Ensure these are defined!) ---\n",
    "def get_question_from_input(inputs: dict) -> str:\n",
    "    \"\"\"Extracts the user question from the Chat format or Flat format.\"\"\"\n",
    "    # Case 1: Chat Format (Your current JSONL)\n",
    "    if \"messages\" in inputs:\n",
    "        for msg in reversed(inputs[\"messages\"]):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                return msg[\"content\"]\n",
    "    # Case 2: Flat Format (CSV style)\n",
    "    return inputs.get(\"question\") or inputs.get(\"Question\") or inputs.get(\"input\") or \"\"\n",
    "\n",
    "def get_ground_truth(reference_outputs: dict) -> str:\n",
    "    \"\"\"Extracts the ground truth answer.\"\"\"\n",
    "    # Case 1: Chat Format\n",
    "    if \"message\" in reference_outputs:\n",
    "        return reference_outputs[\"message\"][\"content\"]\n",
    "    # Case 2: Flat Format\n",
    "    return reference_outputs.get(\"answer\") or reference_outputs.get(\"output\") or \"\"\n",
    "\n",
    "\n",
    "# --- 2. Define the Schema & LLM ---\n",
    "class CorrectnessGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    correct: Annotated[bool, ..., \"True if the answer is correct, False otherwise.\"]\n",
    "\n",
    "correctness_instructions = \"\"\"You are a teacher grading a quiz. You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. Here is the grade criteria to follow:\n",
    "(1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. (2) Ensure that the student answer does not contain any conflicting statements.\n",
    "(3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
    "\n",
    "Correctness:\n",
    "A correctness value of True means that the student's answer meets all of the criteria.\n",
    "A correctness value of False means that the student's answer does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# NOTE: If this errors with \"schema not supported\", set strict=False\n",
    "grader_llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/devstral-2512:free\"\n",
    ").with_structured_output(\n",
    "    CorrectnessGrade, method=\"json_schema\", strict=False \n",
    ")\n",
    "\n",
    "\n",
    "# --- 3. The Updated Evaluator Function ---\n",
    "async def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"An evaluator for RAG answer accuracy\"\"\"\n",
    "    \n",
    "    # ‚úÖ FIX: Use helpers instead of direct dict access\n",
    "    question = get_question_from_input(inputs)\n",
    "    ground_truth = get_ground_truth(reference_outputs)\n",
    "    \n",
    "    # 'outputs' comes from your rag_bot, which is already flat, so this is fine:\n",
    "    student_answer = outputs['answer'] \n",
    "\n",
    "    answers = f\"\"\"\\\n",
    "QUESTION: {question}\n",
    "GROUND TRUTH ANSWER: {ground_truth}\n",
    "STUDENT ANSWER: {student_answer}\"\"\"\n",
    "\n",
    "    # Run evaluator\n",
    "    grade = await grader_llm.ainvoke([\n",
    "        {\"role\": \"system\", \"content\": correctness_instructions},\n",
    "        {\"role\": \"user\", \"content\": answers}\n",
    "    ])\n",
    "    \n",
    "    return grade[\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62755e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# --- Helper Function (Required for these evaluators) ---\n",
    "def get_question_from_input(inputs: dict) -> str:\n",
    "    \"\"\"Extracts the user question from nested Chat format or Flat format.\"\"\"\n",
    "    if \"messages\" in inputs:\n",
    "        for msg in reversed(inputs[\"messages\"]):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                return msg[\"content\"]\n",
    "    return inputs.get(\"question\") or inputs.get(\"Question\") or inputs.get(\"input\") or \"\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. RELEVANCE EVALUATOR\n",
    "# ---------------------------------------------------------\n",
    "class RelevanceGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    relevant: Annotated[bool, ..., \"Provide the score on whether the answer addresses the question\"]\n",
    "\n",
    "relevance_instructions = \"\"\"You are a teacher grading a quiz. You will be given a QUESTION and a STUDENT ANSWER. Here is the grade criteria to follow:\n",
    "(1) Ensure the STUDENT ANSWER is concise and relevant to the QUESTION\n",
    "(2) Ensure the STUDENT ANSWER helps to answer the QUESTION\n",
    "\n",
    "Relevance:\n",
    "A relevance value of True means that the student's answer meets all of the criteria.\n",
    "A relevance value of False means that the student's answer does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "relevance_llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/devstral-2512:free\"\n",
    ").with_structured_output(\n",
    "    RelevanceGrade, method=\"json_schema\", strict=False \n",
    ")\n",
    "\n",
    "async def relevance(inputs: dict, outputs: dict) -> bool:\n",
    "    \"\"\"A simple evaluator for RAG answer helpfulness.\"\"\"\n",
    "    question = get_question_from_input(inputs) # <--- FIX\n",
    "    student_answer = outputs['answer']\n",
    "    \n",
    "    answer = f\"QUESTION: {question}\\nSTUDENT ANSWER: {student_answer}\"\n",
    "    \n",
    "    grade = await relevance_llm.ainvoke([\n",
    "        {\"role\": \"system\", \"content\": relevance_instructions},\n",
    "        {\"role\": \"user\", \"content\": answer}\n",
    "    ])\n",
    "    return grade[\"relevant\"]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. GROUNDEDNESS EVALUATOR\n",
    "# ---------------------------------------------------------\n",
    "class GroundedGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    grounded: Annotated[bool, ..., \"Provide the score on if the answer hallucinates from the documents\"]\n",
    "\n",
    "grounded_instructions = \"\"\"You are a teacher grading a quiz. You will be given FACTS and a STUDENT ANSWER. Here is the grade criteria to follow:\n",
    "(1) Ensure the STUDENT ANSWER is grounded in the FACTS. (2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS.\n",
    "\n",
    "Grounded:\n",
    "A grounded value of True means that the student's answer meets all of the criteria.\n",
    "A grounded value of False means that the student's answer does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "grounded_llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/devstral-2512:free\"\n",
    ").with_structured_output(\n",
    "    GroundedGrade, method=\"json_schema\", strict=False\n",
    ")\n",
    "\n",
    "async def groundedness(inputs: dict, outputs: dict) -> bool:\n",
    "    \"\"\"A simple evaluator for RAG answer groundedness.\"\"\"\n",
    "    # Ensure documents exist\n",
    "    if \"documents\" not in outputs:\n",
    "        return False\n",
    "        \n",
    "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
    "    answer = f\"FACTS: {doc_string}\\nSTUDENT ANSWER: {outputs['answer']}\"\n",
    "    \n",
    "    grade = await grounded_llm.ainvoke([\n",
    "        {\"role\": \"system\", \"content\": grounded_instructions},\n",
    "        {\"role\": \"user\", \"content\": answer}\n",
    "    ])\n",
    "    return grade[\"grounded\"]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. RETRIEVAL RELEVANCE EVALUATOR\n",
    "# ---------------------------------------------------------\n",
    "class RetrievalRelevanceGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    relevant: Annotated[bool, ..., \"True if the retrieved documents are relevant to the question, False otherwise\"]\n",
    "\n",
    "retrieval_relevance_instructions = \"\"\"You are a teacher grading a quiz. You will be given a QUESTION and a set of FACTS provided by the student. Here is the grade criteria to follow:\n",
    "(1) You goal is to identify FACTS that are completely unrelated to the QUESTION\n",
    "(2) If the facts contain ANY keywords or semantic meaning related to the question, consider them relevant\n",
    "(3) It is OK if the facts have SOME information that is unrelated to the question as long as (2) is met\n",
    "\n",
    "Relevance:\n",
    "A relevance value of True means that the FACTS contain ANY keywords or semantic meaning related to the QUESTION and are therefore relevant.\n",
    "A relevance value of False means that the FACTS are completely unrelated to the QUESTION.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "retrieval_relevance_llm = ChatOpenAI(\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"openai/gpt-oss-120b:free\"\n",
    ").with_structured_output(RetrievalRelevanceGrade, method=\"json_schema\", strict=False)\n",
    "\n",
    "async def retrieval_relevance(inputs: dict, outputs: dict) -> bool:\n",
    "    \"\"\"An evaluator for document relevance\"\"\"\n",
    "    question = get_question_from_input(inputs) # <--- FIX\n",
    "    \n",
    "    # Check for empty docs\n",
    "    if \"documents\" not in outputs or not outputs[\"documents\"]:\n",
    "        return False\n",
    "        \n",
    "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
    "    answer = f\"FACTS: {doc_string}\\nQUESTION: {question}\"\n",
    "    \n",
    "    grade = await retrieval_relevance_llm.ainvoke([\n",
    "        {\"role\": \"system\", \"content\": retrieval_relevance_instructions},\n",
    "        {\"role\": \"user\", \"content\": answer}\n",
    "    ])\n",
    "    return grade[\"relevant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bede697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Import your actual graph builder\n",
    "from app.services.graph.graph import build_rag_graph\n",
    "# ‚ùå REMOVE THIS IMPORT: from app.services.graph.tools import UserContext\n",
    "\n",
    "class EvalDocument:\n",
    "    def __init__(self, content):\n",
    "        self.page_content = content\n",
    "\n",
    "async def rag_bot(question: str):\n",
    "    # Use MemorySaver to isolate eval from your real DB\n",
    "    checkpointer = MemorySaver()\n",
    "    app_graph = build_rag_graph(checkpointer)\n",
    "    \n",
    "    thread_id = str(uuid.uuid4())\n",
    "    eval_user_id = \"fc047edd-8907-441b-a0a9-b94926a5d1c6\"\n",
    "    \n",
    "    # ‚úÖ FIX: Pass user_id inside 'configurable' dict\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id,\n",
    "            \"user_id\": eval_user_id \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Run the Graph (No 'context' argument needed anymore)\n",
    "    inputs = {\"messages\": [HumanMessage(content=question)]}\n",
    "    final_state = await app_graph.ainvoke(inputs, config=config)\n",
    "    \n",
    "    # --- EXTRACT OUTPUTS ---\n",
    "    messages = final_state[\"messages\"]\n",
    "    final_answer = messages[-1].content\n",
    "    \n",
    "    retrieved_docs = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            retrieved_docs.append(EvalDocument(msg.content))\n",
    "            \n",
    "    return {\n",
    "        \"answer\": final_answer,\n",
    "        \"documents\": retrieved_docs\n",
    "    }\n",
    "\n",
    "async def target(inputs: dict) -> dict:\n",
    "    # 1. Extract the question safely\n",
    "    question = get_question_from_input(inputs)\n",
    "    \n",
    "    if not question:\n",
    "        raise ValueError(f\"Could not find question in inputs: {inputs.keys()}\")\n",
    "\n",
    "    # 2. Run your bot\n",
    "    return await rag_bot(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cc169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-doc-relevance-v2-922046c5' at:\n",
      "https://smith.langchain.com/o/2f1d8fe1-f343-4b0c-9485-a97483c40c16/datasets/b42fd3d0-942d-446f-818a-99952266f172/compare?selectedSessions=02d1ee73-c3af-4349-8034-11663f88a1dc\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOOP LIMIT REACHED (3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "1it [09:39, 579.25s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2it [11:36, 307.61s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "3it [15:00, 260.35s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "4it [19:08, 255.51s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "5it [20:31, 193.30s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "6it [22:31, 168.24s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "7it [24:30, 152.17s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "8it [28:40, 183.38s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOOP LIMIT REACHED (3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "9it [37:46, 296.56s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "10it [41:44, 278.61s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOOP LIMIT REACHED (3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "11it [48:49, 323.29s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOOP LIMIT REACHED (3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12it [57:00, 374.53s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13it [59:16, 301.99s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "14it [1:01:13, 246.33s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "15it [1:03:11, 207.66s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "16it [1:05:23, 184.70s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "17it [1:06:56, 157.07s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "18it [1:09:49, 162.15s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "19it [1:12:00, 152.61s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "20it [1:13:52, 140.46s/it]INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n",
      "\n",
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n",
      "WARNING:langchain_milvus.vectorstores.milvus:Failed to initialize AsyncMilvusClient during Milvus initialization: <ConnectionConfigException: (code=1, message=Cannot create async connection: no running event loop. Please ensure you are running in an async context.)>. Async operations will be unavailable until AsyncMilvusClient is successfully created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...üîç Tool Execution: Searching docs for User fc047edd-8907-441b-a0a9-b94926a5d1c6...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOOP LIMIT REACHED (3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "20it [1:22:23, 247.16s/it]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m experiment_results = \u001b[38;5;28;01mawait\u001b[39;00m client.aevaluate(\n\u001b[32m      2\u001b[39m     target,\n\u001b[32m      3\u001b[39m     data=dataset_name,\n\u001b[32m      4\u001b[39m     evaluators=[correctness, relevance], \u001b[38;5;66;03m# Add others if you updated them\u001b[39;00m\n\u001b[32m      5\u001b[39m     experiment_prefix=\u001b[33m\"\u001b[39m\u001b[33mrag-doc-relevance-v2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Evaluation Complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\client.py:8579\u001b[39m, in \u001b[36mClient.aevaluate\u001b[39m\u001b[34m(self, target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m   8373\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Evaluate an async target system on a given dataset.\u001b[39;00m\n\u001b[32m   8374\u001b[39m \n\u001b[32m   8375\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   8575\u001b[39m \u001b[33;03m!!! version-added \"Added in `langsmith` 0.2.0\"\u001b[39;00m\n\u001b[32m   8576\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   8577\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_arunner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aevaluate \u001b[38;5;28;01mas\u001b[39;00m aevaluate_\n\u001b[32m-> \u001b[39m\u001b[32m8579\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m aevaluate_(\n\u001b[32m   8580\u001b[39m     target,\n\u001b[32m   8581\u001b[39m     data=data,\n\u001b[32m   8582\u001b[39m     evaluators=evaluators,\n\u001b[32m   8583\u001b[39m     summary_evaluators=summary_evaluators,\n\u001b[32m   8584\u001b[39m     metadata=metadata,\n\u001b[32m   8585\u001b[39m     experiment_prefix=experiment_prefix,\n\u001b[32m   8586\u001b[39m     description=description,\n\u001b[32m   8587\u001b[39m     max_concurrency=max_concurrency,\n\u001b[32m   8588\u001b[39m     num_repetitions=num_repetitions,\n\u001b[32m   8589\u001b[39m     client=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   8590\u001b[39m     blocking=blocking,\n\u001b[32m   8591\u001b[39m     experiment=experiment,\n\u001b[32m   8592\u001b[39m     upload_results=upload_results,\n\u001b[32m   8593\u001b[39m     error_handling=error_handling,\n\u001b[32m   8594\u001b[39m     **kwargs,\n\u001b[32m   8595\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:323\u001b[39m, in \u001b[36maevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    322\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _aevaluate(\n\u001b[32m    324\u001b[39m     target,\n\u001b[32m    325\u001b[39m     data=data,\n\u001b[32m    326\u001b[39m     evaluators=evaluators,\n\u001b[32m    327\u001b[39m     summary_evaluators=summary_evaluators,\n\u001b[32m    328\u001b[39m     metadata=metadata,\n\u001b[32m    329\u001b[39m     experiment_prefix=experiment_prefix,\n\u001b[32m    330\u001b[39m     description=description,\n\u001b[32m    331\u001b[39m     max_concurrency=max_concurrency,\n\u001b[32m    332\u001b[39m     num_repetitions=num_repetitions,\n\u001b[32m    333\u001b[39m     client=client,\n\u001b[32m    334\u001b[39m     blocking=blocking,\n\u001b[32m    335\u001b[39m     experiment=experiment,\n\u001b[32m    336\u001b[39m     upload_results=upload_results,\n\u001b[32m    337\u001b[39m     error_handling=error_handling,\n\u001b[32m    338\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:534\u001b[39m, in \u001b[36m_aevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m    532\u001b[39m results = AsyncExperimentResults(manager)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blocking:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m results.wait()\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:1236\u001b[39m, in \u001b[36mAsyncExperimentResults.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1236\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:1208\u001b[39m, in \u001b[36mAsyncExperimentResults._process_data\u001b[39m\u001b[34m(self, manager)\u001b[39m\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, manager: _AsyncExperimentManager) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1207\u001b[39m     tqdm = _load_tqdm()\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(manager.aget_results()):\n\u001b[32m   1209\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m   1210\u001b[39m             \u001b[38;5;28mself\u001b[39m._results.append(item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\tqdm\\asyncio.py:42\u001b[39m, in \u001b[36mtqdm_asyncio.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterable_awaitable:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         res = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterable_next()\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     44\u001b[39m         res = \u001b[38;5;28mself\u001b[39m.iterable_next()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:894\u001b[39m, in \u001b[36m_AsyncExperimentManager.aget_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> AsyncIterator[ExperimentResultRow]:\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m run, example, evaluation_results \u001b[38;5;129;01min\u001b[39;00m aitertools.async_zip(\n\u001b[32m    895\u001b[39m         \u001b[38;5;28mself\u001b[39m.aget_runs(), \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aget_examples(), \u001b[38;5;28mself\u001b[39m.aget_evaluation_results()\n\u001b[32m    896\u001b[39m     ):\n\u001b[32m    897\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m ExperimentResultRow(\n\u001b[32m    898\u001b[39m             run=run,\n\u001b[32m    899\u001b[39m             example=example,\n\u001b[32m    900\u001b[39m             evaluation_results=evaluation_results,\n\u001b[32m    901\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\_internal\\_aiter.py:221\u001b[39m, in \u001b[36masync_zip\u001b[39m\u001b[34m(*async_iterables)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         items = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    222\u001b[39m             *(py_anext(iterator) \u001b[38;5;28;01mfor\u001b[39;00m iterator \u001b[38;5;129;01min\u001b[39;00m iterators)\n\u001b[32m    223\u001b[39m         )\n\u001b[32m    224\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(items)\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\_internal\\_aiter.py:103\u001b[39m, in \u001b[36mtee_peer\u001b[39m\u001b[34m(iterator, buffer, peers, lock)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     item = \u001b[38;5;28;01mawait\u001b[39;00m iterator.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_arunner.py:844\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    835\u001b[39m experiment_results = aitertools.aiter_with_concurrency(\n\u001b[32m    836\u001b[39m     max_concurrency,\n\u001b[32m    837\u001b[39m     process_examples(),\n\u001b[32m    838\u001b[39m     _eager_consumption_timeout=\u001b[32m0.001\u001b[39m,\n\u001b[32m    839\u001b[39m )\n\u001b[32m    841\u001b[39m r1, r2, r3 = aitertools.atee(experiment_results, \u001b[32m3\u001b[39m, lock=asyncio.Lock())\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copy(\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     (result[\u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r1),\n\u001b[32m    845\u001b[39m     runs=(result[\u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r2),\n\u001b[32m    846\u001b[39m     evaluation_results=(result[\u001b[33m\"\u001b[39m\u001b[33mevaluation_results\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r3),\n\u001b[32m    847\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\CustomRAG\\.venv\\Lib\\site-packages\\langsmith\\_internal\\_aiter.py:97\u001b[39m, in \u001b[36mtee_peer\u001b[39m\u001b[34m(iterator, buffer, peers, lock)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buffer:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m     98\u001b[39m             \u001b[38;5;66;03m# Another peer produced an item while we were waiting for the lock.\u001b[39;00m\n\u001b[32m     99\u001b[39m             \u001b[38;5;66;03m# Proceed with the next loop iteration to yield the item.\u001b[39;00m\n\u001b[32m    100\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m buffer:\n\u001b[32m    101\u001b[39m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fenaz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:14\u001b[39m, in \u001b[36m_ContextManagerMixin.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.acquire()\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# statement for locks.\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Fenaz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\locks.py:113\u001b[39m, in \u001b[36mLock.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    115\u001b[39m         \u001b[38;5;28mself\u001b[39m._waiters.remove(fut)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "experiment_results = await client.aevaluate(\n",
    "    target,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness, relevance, groundedness, retrieval_relevance], # Add others if you updated them\n",
    "    experiment_prefix=\"rag-doc-relevance-v2\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Evaluation Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f206d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = experiment_results.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0589ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Key loaded: sk-or-v1... (length: 73)\n",
      "\n",
      "üì° Connecting to https://openrouter.ai/api/v1/chat/completions...\n",
      "Status Code: 404\n",
      "‚ùå FAILED.\n",
      "Error Response: {\"error\":{\"message\":\"No endpoints found matching your data policy (Free model publication). Configure: https://openrouter.ai/settings/privacy\",\"code\":404}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['ch_sim','en']) # this needs to run only once to load the model into memory\n",
    "result = reader.readtext('chinese.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
